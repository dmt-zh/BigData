# BIG DATA

## Выполнение заданий в рамках специализации [Инженер данных](https://karpov.courses/dataengineer)

Mеханизмы распределённого хранения больших данных на базе Hadoop, основные паттерны реализации их распределённой обработки. Вопросы отказоустойчивости и восстановления после сбоев. Потоковая обработка данных, методы и средства мониторинга и профилирования заданий Spark.

## Модули специализации:
- [Проектирование DWH](https://github.com/dmt-zh/SQL-and-DB/tree/main/db_design/dwh)
- Реляционные и MPP СУБД
- Автоматизация ETL-процессов
- Big Data: [Hadoop](https://github.com/dmt-zh/BigData/tree/main/Hadoop), [PySpark](https://github.com/dmt-zh/BigData/tree/main/PySpark)
- [Kafkа. Spark streaming](https://github.com/dmt-zh/BigData/tree/main/Kafka)
- [Data Pipeline](https://github.com/dmt-zh/BigData/tree/main/DataPipeline): Data Lake (S3), DWH (Greenplum), Airflow, Spark (Kubernetes), GitLab